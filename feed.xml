<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
<title>Schemescape</title>
<id>https://log.schemescape.com/</id>
<link rel="self" href="https://log.schemescape.com/feed.xml"/>
<link rel="alternate" href="https://log.schemescape.com/"/>
<author>
<name>Schemescape</name>
</author>
<updated>2022-08-12T18:46:15.329Z</updated>

<entry>
<title>Porting a browser-based game to Steam</title>
<id>https://log.schemescape.com/posts/game-development/browser-based-game-on-steam.html</id>
<link rel="alternate" href="https://log.schemescape.com/posts/game-development/browser-based-game-on-steam.html"/>
<updated>2022-08-10T00:00:00.000Z</updated>
<summary type="text">I&apos;m researching options for porting a browser-based game to Steam.</summary>
<content type="html">&lt;p&gt;Browser-based games are great because players can pick them up and start playing without having to install anything (assuming reasonable cross-browser compatibility). HTML can also be convenient for UI, especially for laying out text (although handling CSS and rendering quirks can be frustrating).&lt;/p&gt;
&lt;p&gt;Despite the benefits, I&amp;#39;d like to port my most popular browser-based game to Steam, for the following reasons:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;I want players to be able to sync their data across devices, without forcing them to create a new account (and without me having to host everything)&lt;/li&gt;
&lt;li&gt;I want Steam&amp;#39;s huge user base to be able to access my game (more for convenience than for exposure)&lt;/li&gt;
&lt;li&gt;I might want to build on this experience in the future, for example, if I&amp;#39;d like to sell a game&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&quot;open-questions&quot;&gt;Open questions&lt;/h1&gt;
&lt;p&gt;I have no experience developing for or publishing on Steam, so I have a lot of questions:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Which browser-to-native framework should I use (Electron, Tauri, WebView2, etc.)?&lt;/li&gt;
&lt;li&gt;Does Steam have built-in support for browser-based titles? Are any of the above frameworks in the Steamworks Common Redistributables package?&lt;/li&gt;
&lt;li&gt;Which platforms should I support?&lt;/li&gt;
&lt;li&gt;What&amp;#39;s required to take advantage of Steam&amp;#39;s support for cloud saves/syncing?&lt;/li&gt;
&lt;li&gt;How do I test Steam Cloud saves?&lt;/li&gt;
&lt;li&gt;Is there any way to transition user information from the current web site to the Steam release?&lt;/li&gt;
&lt;li&gt;Will it end up costing more than the advertised $100? Is there any way to bring that cost down?&lt;/li&gt;
&lt;li&gt;Is it permissible to promote the Steam version of the game from its current web-based host?&lt;/li&gt;
&lt;li&gt;What sort of analytics does Steam provide for game publishers?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Answering these questions will take some time, but honestly I think I&amp;#39;d regret not ever trying to port my game to Steam.&lt;/p&gt;
&lt;h1 id=&quot;first-steps&quot;&gt;First steps&lt;/h1&gt;
&lt;p&gt;Steam publishes documentation for Steamworks here:&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://partner.steamgames.com/doc/home&quot;&gt;https://partner.steamgames.com/doc/home&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;common-redistributables&quot;&gt;Common redistributables&lt;/h2&gt;
&lt;p&gt;There is &lt;a href=&quot;https://partner.steamgames.com/doc/features/common_redist&quot;&gt;a page about common redistributables&lt;/a&gt; that says it includes &amp;quot;Microsoft Visual C++, .NET, DirectX 9, OpenAL, XNA, and PhysX&amp;quot;, but it says the complete, up to date list is on a page that appears to only be visible to developers who have already paid a $100 fee. I had planned to pay the fee regardless, but I&amp;#39;d hoped I could at least answer some of my questions before handing over money.&lt;/p&gt;
&lt;h2 id=&quot;platforms&quot;&gt;Platforms&lt;/h2&gt;
&lt;p&gt;It&amp;#39;s now possible to download the Steamworks SDK &lt;em&gt;before&lt;/em&gt; paying the Steam Direct fee, which is helpful. Within that zip file, it has binaries for 32- and 64-bit Linux and Windows, and macOS. I&amp;#39;m interpreting that list to be the definitive list of supported platforms.&lt;/p&gt;
&lt;p&gt;Note that GPL-licensed libraries can&amp;#39;t be linked with the Steamworks SDK (or probably distributed via Steam period).&lt;/p&gt;
&lt;h2 id=&quot;cloud-saves&quot;&gt;Cloud saves&lt;/h2&gt;
&lt;p&gt;The Steam SDK &lt;a href=&quot;https://partner.steamgames.com/doc/sdk/api&quot;&gt;provides a C++ interface&lt;/a&gt; for enumerating/reading/writing files to the Steam Cloud. There is also an &lt;a href=&quot;https://partner.steamgames.com/doc/features/cloud#steam_auto-cloud&quot;&gt;auto-cloud&lt;/a&gt; feature that just synchronizes files based on path.&lt;/p&gt;
&lt;p&gt;As far as transitioning data from the browser version to the Steam version, I doubt there is a reliable and automatic way to do so.&lt;/p&gt;
&lt;h3 id=&quot;one-note-on-itch&quot;&gt;One note on Itch&lt;/h3&gt;
&lt;p&gt;Note: in the past, I investigated using &lt;a href=&quot;https://itch.io/&quot;&gt;Itch&lt;/a&gt;&amp;#39;s launcher to sync user data, but there were many issues:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Obtaining the user identity isn&amp;#39;t possible due to known bugs&lt;/li&gt;
&lt;li&gt;Storing data is up to the game developer, because Itch (reasonably, in my opinion) does not offer cloud storage for games&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;cost&quot;&gt;Cost&lt;/h2&gt;
&lt;p&gt;As far as I can tell, Steam&amp;#39;s $100 fee (plus tax) is a one-time fee. Obviously, I&amp;#39;d prefer not to have to shell out this much money, but, luckily, $100 is not going to make or break my financial situation.&lt;/p&gt;
&lt;h2 id=&quot;advertising-steam-release-within-browser-based-version&quot;&gt;Advertising Steam release within browser-based version&lt;/h2&gt;
&lt;p&gt;It seems that there is precedent (e.g. &lt;a href=&quot;https://anuke.itch.io/mindustry&quot;&gt;Mindustry on Itch&lt;/a&gt;) for advertising that the same game is available on Steam, when the Steam version has additional features. I didn&amp;#39;t see anything Itch&amp;#39;s terms of service that prohibit this (nor do I think it &lt;em&gt;should&lt;/em&gt; be prohibited).&lt;/p&gt;
&lt;h1 id=&quot;marketing-and-analytics&quot;&gt;Marketing and analytics&lt;/h1&gt;
&lt;p&gt;Steam has &lt;a href=&quot;https://partner.steamgames.com/doc/marketing&quot;&gt;guidance for marketing games on the platform&lt;/a&gt;. It looks like there is support for Google Analytics and some link tracking. For now, I&amp;#39;m just going to put off thinking about marketing because my goal is to share my game, not to get rich off of it.&lt;/p&gt;
</content>
</entry>
<entry>
<title>May 16th, 2022</title>
<id>https://log.schemescape.com/posts/misc/2022-05-16.html</id>
<link rel="alternate" href="https://log.schemescape.com/posts/misc/2022-05-16.html"/>
<updated>2022-05-16T00:00:00.000Z</updated>
<summary type="text">A memory, for my own reference.</summary>
<content type="html">&lt;p&gt;I had just been there the previous day, but after receiving an inevitable update, I was returning once again. Inevitable or not, I was never able to imagine it actually happening.&lt;/p&gt;
&lt;p&gt;It was one of the few sunny days of an unusually cold spring. I was driving down a mostly empty freeway in the evening. I&amp;#39;d made this drive many times before, but this time was different.&lt;/p&gt;
&lt;p&gt;I&amp;#39;m still not sure how to feel about it, and I&amp;#39;m not convinced that there even &lt;em&gt;is&lt;/em&gt; a way one should feel about it.&lt;/p&gt;
&lt;p&gt;Regardless, it puts things into perspective.&lt;/p&gt;
</content>
</entry>
<entry>
<title>Generating music using machine learning (part 2)</title>
<id>https://log.schemescape.com/posts/machine-learning/generating-music-2.html</id>
<link rel="alternate" href="https://log.schemescape.com/posts/machine-learning/generating-music-2.html"/>
<updated>2022-05-02T00:00:00.000Z</updated>
<summary type="text">An unsuccessful (but less unsuccessful than last time) attempt to generate ragtime music.</summary>
<content type="html">&lt;p&gt;In &lt;a href=&quot;https://log.schemescape.com/posts/machine-learning/generating-music.html&quot;&gt;part 1&lt;/a&gt;, I played around with pre-trained &lt;a href=&quot;https://magenta.tensorflow.org/music-transformer&quot;&gt;Music Transformer&lt;/a&gt; models, in an attempt to generate a piece of ragtime piano music. The results were interesting, but the musical styles were random (and internally inconsistent).&lt;/p&gt;
&lt;p&gt;In this part, I attempt to train my own Music Transformer model, using a ragtime-focused corpus.&lt;/p&gt;
&lt;h1 id=&quot;first-attempt&quot;&gt;First attempt&lt;/h1&gt;
&lt;p&gt;Initially, I tried to generate music using the official Music Transformer environment, &lt;a href=&quot;https://magenta.tensorflow.org/&quot;&gt;Magenta&lt;/a&gt;, following instructions in &lt;a href=&quot;https://groups.google.com/a/tensorflow.org/g/magenta-discuss/c/tRrth7wXF6U&quot;&gt;an email thread about using transfer learning with Music Transformer&amp;#39;s pre-trained checkpoints&lt;/a&gt;. I hit several issues:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/magenta/magenta/issues/1962&quot;&gt;Magenta install fails for Python &amp;gt;= 3.8 &lt;/a&gt; (worked around via &lt;a href=&quot;https://www.anaconda.com/&quot;&gt;Anaconda&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;The default optimizer (&lt;code&gt;AdafactorOptimizer&lt;/code&gt;) appeared to be incompatible with the version of Tensorflow Magenta installed (worked around via &lt;code&gt;--hparams=optimizer=Adam,...&lt;/code&gt;)&lt;/li&gt;
&lt;li&gt;I couldn&amp;#39;t use my GPU to train because it didn&amp;#39;t have enough memory&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/magenta/magenta/issues/1862&quot;&gt;Tensor2Tensor terminated on &amp;quot;key not found&amp;quot; errors&lt;/a&gt; (worked around with a newer version, as noted in the linked GitHub issue)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;results&quot;&gt;Results&lt;/h2&gt;
&lt;p&gt;After training for roughly a day (2,500 steps), the &lt;a href=&quot;https://log.schemescape.com/posts/machine-learning/../../assets/music-generation/mt-train-2500.mid&quot;&gt;resulting MIDI&lt;/a&gt; sounds mostly like random noise. It&amp;#39;s not clear to me if this was due to a bug in my pipeline or if I just needed to spend a lot more time training.&lt;/p&gt;
&lt;p&gt;Ultimately, I decided I didn&amp;#39;t understand the Magenta and Tensor2Tensor libraries well enough to make much progress (without investing an excessive amount of time), and I&amp;#39;d spent enough time troubleshooting issues already. &lt;a href=&quot;https://github.com/jaredkrinke/music-transformer-fine-tuning&quot;&gt;My training scripts are here&lt;/a&gt;.&lt;/p&gt;
&lt;h1 id=&quot;second-attempt&quot;&gt;Second attempt&lt;/h1&gt;
&lt;p&gt;Rather than give up on transformer-based music generation entirely, I searched around for a simpler codebase that I might be able to more easily understand and/or adapt. Here are a few I ran across:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/davidsvy/transformer-xl&quot;&gt;transformer-xl&lt;/a&gt; by &lt;a href=&quot;https://github.com/davidsvy&quot;&gt;davidsvy&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/COMP6248-Reproducability-Challenge/music-transformer-comp6248&quot;&gt;music-transformer-comp6248
&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/bearpelican/musicautobot&quot;&gt;MusicAutobot&lt;/a&gt; by &lt;a href=&quot;https://github.com/bearpelican&quot;&gt;Andrew Shaw&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The first one is a noted as a re-implementation from scratch of the ideas from the transformer/attention research papers (mostly the same ones I&amp;#39;d been looking at) using Tensorflow/Keras. The codebase seemed small enough that I could probably understand it all without too much trouble.&lt;/p&gt;
&lt;p&gt;I decided to move forward with the transformer-xl repository. I didn&amp;#39;t hit any issues with setup, which was a welcome development.&lt;/p&gt;
&lt;h2 id=&quot;training&quot;&gt;Training&lt;/h2&gt;
&lt;p&gt;As an initial test, I tried training on a fairly small corpus of 58 Scott Joplin MIDIs. I was able to decrease the batch size slightly to support training on my roughly 7 year old GPU. Training for 100 epochs only took about 7 hours.&lt;/p&gt;
&lt;p&gt;Note: although there was a preprocessing step to convert the MIDI files to another format, I didn&amp;#39;t notice any data generation/augmentation, as in the Magenta codebase.&lt;/p&gt;
&lt;h2 id=&quot;initial-results&quot;&gt;Initial results&lt;/h2&gt;
&lt;p&gt;Generating results was surprisingly slow (compared to using Magenta), but I haven&amp;#39;t investigated the reason for that yet.&lt;/p&gt;
&lt;p&gt;Regardless, the results sounded a (little) bit like music--a huge improvement from my previous attempt (which was just noise). Examples:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://log.schemescape.com/posts/machine-learning/../../assets/music-generation/train-100-1.midi&quot;&gt;Example 1&lt;/a&gt;: occasional glimpses of music&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://log.schemescape.com/posts/machine-learning/../../assets/music-generation/train-100-2.midi&quot;&gt;Example 2&lt;/a&gt;: pleasant notes with essentially no rhythm&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://log.schemescape.com/posts/machine-learning/../../assets/music-generation/train-100-3.midi&quot;&gt;Example 3&lt;/a&gt;: repetitive, again with inconsistent rhythm&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Unfortunately, the results after 250 epochs weren&amp;#39;t noticeably any better. It&amp;#39;s possible that the small corpus isn&amp;#39;t sufficient for training this model.&lt;/p&gt;
&lt;h1 id=&quot;next-steps&quot;&gt;Next steps&lt;/h1&gt;
&lt;p&gt;I started this project for fun, but after struggling with Python environments and coming to the realization that I have insufficient compute resources available, I&amp;#39;m reconsidering whether or not this is a good use of my time.&lt;/p&gt;
</content>
</entry>
<entry>
<title>Generating music using machine learning</title>
<id>https://log.schemescape.com/posts/machine-learning/generating-music.html</id>
<link rel="alternate" href="https://log.schemescape.com/posts/machine-learning/generating-music.html"/>
<updated>2022-04-26T00:00:00.000Z</updated>
<summary type="text">Let&apos;s see if I can use Google Brain&apos;s Music Transformer to generate ragtime music.</summary>
<content type="html">&lt;p&gt;Recent music generation results (e.g. &lt;a href=&quot;https://magenta.tensorflow.org/music-transformer&quot;&gt;Music Transformer: Generating Music with Long-Term Structure&lt;/a&gt;) are part of what piqued my interest in machine learning. After &lt;a href=&quot;https://log.schemescape.com/posts/machine-learning/mitx-6.036.html&quot;&gt;following an introduction to machine learning&lt;/a&gt;, it&amp;#39;s time for some experimentation.&lt;/p&gt;
&lt;p&gt;First up: generating a &lt;a href=&quot;https://en.wikipedia.org/wiki/Ragtime&quot;&gt;ragtime&lt;/a&gt; piano piece.&lt;/p&gt;
&lt;h1 id=&quot;approaches&quot;&gt;Approaches&lt;/h1&gt;
&lt;p&gt;The most compelling generated music I&amp;#39;ve seen thus far comes from Google Brain, namely their &lt;a href=&quot;https://magenta.tensorflow.org/performance-rnn&quot;&gt;Performance RNN&lt;/a&gt; and &lt;a href=&quot;https://magenta.tensorflow.org/music-transformer&quot;&gt;Music Transformer&lt;/a&gt; papers. The associated GitHub repositories appear to contain models that have been pre-trained on various corpora (e.g. a &lt;a href=&quot;https://www.piano-e-competition.com/&quot;&gt;piano competition&amp;#39;s MIDI recordings&lt;/a&gt;). It&amp;#39;s also possible to train using a new corpus. The trained models can generate continuations based on a primer or generate unconditioned music &amp;quot;from scratch&amp;quot;.&lt;/p&gt;
&lt;p&gt;Here are several approaches I&amp;#39;m investigating for generating a ragtime piece:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Condition pre-trained Performance RNN and Music Transformer models with existing ragtime music (either an intro or the first few measures) and generate a continuation&lt;/li&gt;
&lt;li&gt;Train a new model on a corpus of ragtime music, and then do unconditioned generation&lt;/li&gt;
&lt;li&gt;Train a new model on a ragtime corpus and generate a continuation from a ragtime primer&lt;/li&gt;
&lt;li&gt;Train a new model on a ragtime corpus and generate a continuation from an arbitrary primer&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;I don&amp;#39;t have any intuition for how large of a corpus is required to generate a decent model, so it&amp;#39;s possible that options 2 - 4 won&amp;#39;t be feasible for me (either because finding/generating such a training corpus is too difficult or the compute required to train the model is beyond what my computer can handle).&lt;/p&gt;
&lt;h1 id=&quot;using-pre-trained-models&quot;&gt;Using pre-trained models&lt;/h1&gt;
&lt;p&gt;Without installing anything locally, you can use the &lt;a href=&quot;https://colab.research.google.com/notebooks/magenta/piano_transformer/piano_transformer.ipynb&quot;&gt;Music Transformer notebook&lt;/a&gt; to generate music. There are several options:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Generate music &amp;quot;from scratch&amp;quot; (unconditional)&lt;/li&gt;
&lt;li&gt;Generate a continuation based on a primer&lt;/li&gt;
&lt;li&gt;Generate accompaniment for a (monophonic) melody&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;unconditional-generation&quot;&gt;Unconditional generation&lt;/h2&gt;
&lt;p&gt;Without providing a primer, I don&amp;#39;t think it&amp;#39;s possible to indicate what genre of music you&amp;#39;d like to generate. For example, the clip I got sounds like some sort of &lt;a href=&quot;https://log.schemescape.com/posts/machine-learning/../../assets/music-generation/mt-unconditioned.mid&quot;&gt;boogie-woogie folk march&lt;/a&gt;. Obviously this isn&amp;#39;t the genre that I was looking for (or, really, than anyone was looking for). Rather than continuing on randomly like this, I&amp;#39;ll investigate primed generation.&lt;/p&gt;
&lt;h2 id=&quot;continuations&quot;&gt;Continuations&lt;/h2&gt;
&lt;p&gt;The notebook linked above also supports providing a primer, either from a provided list or by uploading a MIDI file directly in the UI.&lt;/p&gt;
&lt;h3 id=&quot;cropping-midi-primers&quot;&gt;Cropping MIDI primers&lt;/h3&gt;
&lt;p&gt;The primer is included in the output, so I assume it should be reasonably short. My original plan was to edit down an existing ragtime MIDI using &lt;a href=&quot;https://musescore.org/en&quot;&gt;MuseScore&lt;/a&gt;, but MuseScore&amp;#39;s output appears to be incompatible with the &lt;a href=&quot;http://craffel.github.io/pretty-midi/&quot;&gt;pretty_midi&lt;/a&gt; module that the notebook uses, resulting in the following error:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;pretty_midi\pretty_midi.py:&lt;span class=&quot;hljs-number&quot;&gt;97&lt;/span&gt;: RuntimeWarning: Tempo, Key &lt;span class=&quot;hljs-keyword&quot;&gt;or&lt;/span&gt; &lt;span class=&quot;hljs-type&quot;&gt;Time&lt;/span&gt; signature change events &lt;span class=&quot;hljs-built_in&quot;&gt;found&lt;/span&gt; &lt;span class=&quot;hljs-keyword&quot;&gt;on&lt;/span&gt; non-zero tracks. This &lt;span class=&quot;hljs-keyword&quot;&gt;is&lt;/span&gt; &lt;span class=&quot;hljs-keyword&quot;&gt;not&lt;/span&gt; a &lt;span class=&quot;hljs-keyword&quot;&gt;valid&lt;/span&gt; &lt;span class=&quot;hljs-keyword&quot;&gt;type&lt;/span&gt; &lt;span class=&quot;hljs-number&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;hljs-keyword&quot;&gt;or&lt;/span&gt; &lt;span class=&quot;hljs-keyword&quot;&gt;type&lt;/span&gt; &lt;span class=&quot;hljs-number&quot;&gt;1&lt;/span&gt; MIDI file. Tempo, Key &lt;span class=&quot;hljs-keyword&quot;&gt;or&lt;/span&gt; &lt;span class=&quot;hljs-type&quot;&gt;Time&lt;/span&gt; Signature may be wrong.
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;My workaround was to switch to using &lt;a href=&quot;https://www.audacityteam.org/&quot;&gt;Audacity&lt;/a&gt; to crop my MIDI primer (and this worked without issue).&lt;/p&gt;
&lt;h3 id=&quot;example-continuations&quot;&gt;Example continuations&lt;/h3&gt;
&lt;p&gt;First, I tried using just the intro bars of some Scott Joplin rags:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://log.schemescape.com/posts/machine-learning/../../assets/music-generation/mt-continuation-intro-wall-street.mid&quot;&gt;Wall Street Rag intro&lt;/a&gt;: this generated an interesting continuation that sounded vaguely like a cross between ragtime and new age piano&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://log.schemescape.com/posts/machine-learning/../../assets/music-generation/mt-continuation-intro-magnetic.mid&quot;&gt;Magnetic Rag intro&lt;/a&gt;: this generated a continuation with a halting style that keeps repeating notes&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Overall, the results are impressive, but also somewhat alien. And definitely not ragtime.&lt;/p&gt;
&lt;p&gt;Next, I tried supplying the beginning of a few sections of Joplin rags:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Wall Street Rag&lt;ul&gt;
&lt;li&gt;The &lt;a href=&quot;https://log.schemescape.com/posts/machine-learning/../../assets/music-generation/mt-continuation-wall-street-1.mid&quot;&gt;first continuation&lt;/a&gt; gets a bit stuck on the primer, but then recovers nicely into a very short still-not-quite-ragtime section&lt;/li&gt;
&lt;li&gt;The &lt;a href=&quot;https://log.schemescape.com/posts/machine-learning/../../assets/music-generation/mt-continuation-wall-street-2.mid&quot;&gt;second continuation&lt;/a&gt; strays quickly and widely from ragtime (continuing the trend of &amp;quot;impressive, but not what I wanted&amp;quot;)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Maple Leaf Rag&lt;ul&gt;
&lt;li&gt;This &lt;a href=&quot;https://log.schemescape.com/posts/machine-learning/../../assets/music-generation/mt-continuation-maple-leaf.mid&quot;&gt;continuation&lt;/a&gt; seemed to ignore the primer and just started cycling through music I can only describe as &amp;quot;movie soundtrack&amp;quot;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Magnetic Rag&lt;ul&gt;
&lt;li&gt;The &lt;a href=&quot;https://log.schemescape.com/posts/machine-learning/../../assets/music-generation/mt-continuation-magnetic-1.mid&quot;&gt;first continuation&lt;/a&gt; was short, but rag-like!&lt;/li&gt;
&lt;li&gt;The &lt;a href=&quot;https://log.schemescape.com/posts/machine-learning/../../assets/music-generation/mt-continuation-magnetic-2.mid&quot;&gt;second continuation&lt;/a&gt; was similarly short, but promising&lt;/li&gt;
&lt;li&gt;The &lt;a href=&quot;https://log.schemescape.com/posts/machine-learning/../../assets/music-generation/mt-continuation-magnetic-3.mid&quot;&gt;third continuation&lt;/a&gt; was much longer, but... bad&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;accompaniment&quot;&gt;Accompaniment&lt;/h2&gt;
&lt;p&gt;Out of curiosity, I also tried generating an accompaniment (based on a monophonic melody that consists of the highest non-overlapping notes in the cropped MIDIs from the last section):&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://log.schemescape.com/posts/machine-learning/../../assets/music-generation/mt-accompaniment-magnetic.mid&quot;&gt;Magnetic Rag accompaniment&lt;/a&gt;: this was a baroquely ornamented mix of classical and blues&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;reflecting-on-pre-trained-models&quot;&gt;Reflecting on pre-trained models&lt;/h2&gt;
&lt;p&gt;Unsurprisingly, the generic pre-trained models I used, while undoubtedly impressive, seem best suited for exploration and amusement, rather than producing something focused on a particular genre.&lt;/p&gt;
&lt;p&gt;I suspect that the best path forward for this experiment is to train a new ragtime-focused model on a corpus of typical ragtime MIDIs. As noted earlier, it&amp;#39;s possible I won&amp;#39;t be able to find either a large enough corpus or enough compute power to produce a reasonable model, but if I &lt;em&gt;do&lt;/em&gt; succeed, I think the results will be more consistently rag-like.&lt;/p&gt;
</content>
</entry>
<entry>
<title>MITx - 6.036: Introduction to Machine Learning</title>
<id>https://log.schemescape.com/posts/machine-learning/mitx-6.036.html</id>
<link rel="alternate" href="https://log.schemescape.com/posts/machine-learning/mitx-6.036.html"/>
<updated>2022-04-24T00:00:00.000Z</updated>
<summary type="text">I&apos;m following a freely available MIT coure: Introduction to Machine Learning.</summary>
<content type="html">&lt;p&gt;As &lt;a href=&quot;https://log.schemescape.com/posts/machine-learning/getting-started.html&quot;&gt;noted previously&lt;/a&gt;, I&amp;#39;ve been researching machine learning (just for fun).&lt;/p&gt;
&lt;h1 id=&quot;mitx---6036&quot;&gt;MITx - 6.036&lt;/h1&gt;
&lt;p&gt;I&amp;#39;m starting with an undergraduate course from MIT that is online for free: &lt;a href=&quot;https://openlearninglibrary.mit.edu/courses/course-v1:MITx+6.036+1T2019/about&quot;&gt;MITx - 6.036: Introduction to Machine Learning&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Having just completed the course, here are some observations:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The lectures are excellent, but note that they&amp;#39;re theory- and math-heavy (and my math was rustier than I realized)&lt;/li&gt;
&lt;li&gt;I&amp;#39;d recommend learning about &lt;a href=&quot;https://numpy.org/&quot;&gt;NumPy&lt;/a&gt; &lt;em&gt;prior&lt;/em&gt; to starting this course (especially &lt;a href=&quot;https://numpy.org/doc/stable/user/basics.broadcasting.html&quot;&gt;element-wise operations and broadcasting&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;So far, there has been no need (and no benefit) to enabling GPU acceleration (and setting it up on Windows was painful, for &lt;a href=&quot;https://github.com/tensorflow/tensorflow/issues/48868&quot;&gt;reasons I still don&amp;#39;t understand&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;The provided code seems to be built for a previous version of TensorFlow&amp;#39;s Keras interface (although the &lt;a href=&quot;https://gist.github.com/jaredkrinke/0fed897dfbdf35af2c4eb388bfe0d754&quot;&gt;updates I have needed thus far&lt;/a&gt; were minor)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The course provides a great introduction to:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Classification&lt;/li&gt;
&lt;li&gt;Regression&lt;/li&gt;
&lt;li&gt;Neural networks&lt;/li&gt;
&lt;li&gt;Convolutional neural networks&lt;/li&gt;
&lt;li&gt;Recurrent neural networks&lt;/li&gt;
&lt;li&gt;Recommender systems&lt;/li&gt;
&lt;li&gt;Decision trees&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Note that the course &lt;em&gt;doesn&amp;#39;t&lt;/em&gt; cover some of the machine learning topics I&amp;#39;m most interested in:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Transformer_(machine_learning_model)&quot;&gt;Transformers&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Generative_adversarial_network&quot;&gt;Generative adversarial networks&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Overall, it was a fun course and good Python practice, but I wasn&amp;#39;t really inspired to go start a machine learning project because I&amp;#39;m not terribly interested in classification and regression problems at the moment.&lt;/p&gt;
</content>
</entry>
</feed>
