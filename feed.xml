<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
<title>Schemescape</title>
<id>https://log.schemescape.com/</id>
<link rel="self" href="https://log.schemescape.com/feed.xml"/>
<link rel="alternate" href="https://log.schemescape.com/"/>
<author>
<name>Schemescape</name>
</author>
<updated>2022-06-02T22:06:24.499Z</updated>

<entry>
<title>May 16th, 2022</title>
<id>https://log.schemescape.com/posts/misc/2022-05-16.html</id>
<link rel="alternate" href="https://log.schemescape.com/posts/misc/2022-05-16.html"/>
<updated>2022-05-16T00:00:00.000Z</updated>
<summary type="text">A memory, for my own reference.</summary>
<content type="html">&lt;p&gt;I had just been there the previous day, but after receiving an inevitable update, I was returning once again. Inevitable or not, I was never able to imagine it actually happening.&lt;/p&gt;
&lt;p&gt;It was one of the few sunny days of an unusually cold spring. I was driving down a mostly empty freeway in the evening. I&amp;#39;d made this drive many times before, but this time was different.&lt;/p&gt;
&lt;p&gt;I&amp;#39;m still not sure how to feel about it, and I&amp;#39;m not convinced that there even &lt;em&gt;is&lt;/em&gt; a way one should feel about it.&lt;/p&gt;
&lt;p&gt;Regardless, it puts things into perspective.&lt;/p&gt;
</content>
</entry>
<entry>
<title>Generating music using machine learning (part 2)</title>
<id>https://log.schemescape.com/posts/machine-learning/generating-music-2.html</id>
<link rel="alternate" href="https://log.schemescape.com/posts/machine-learning/generating-music-2.html"/>
<updated>2022-05-02T00:00:00.000Z</updated>
<summary type="text">An unsuccessful (but less unsuccessful than last time) attempt to generate ragtime music.</summary>
<content type="html">&lt;p&gt;In &lt;a href=&quot;https://log.schemescape.com/posts/machine-learning/generating-music.html&quot;&gt;part 1&lt;/a&gt;, I played around with pre-trained &lt;a href=&quot;https://magenta.tensorflow.org/music-transformer&quot;&gt;Music Transformer&lt;/a&gt; models, in an attempt to generate a piece of ragtime piano music. The results were interesting, but the musical styles were random (and internally inconsistent).&lt;/p&gt;
&lt;p&gt;In this part, I attempt to train my own Music Transformer model, using a ragtime-focused corpus.&lt;/p&gt;
&lt;h1 id=&quot;first-attempt&quot;&gt;First attempt&lt;/h1&gt;
&lt;p&gt;Initially, I tried to generate music using the official Music Transformer environment, &lt;a href=&quot;https://magenta.tensorflow.org/&quot;&gt;Magenta&lt;/a&gt;, following instructions in &lt;a href=&quot;https://groups.google.com/a/tensorflow.org/g/magenta-discuss/c/tRrth7wXF6U&quot;&gt;an email thread about using transfer learning with Music Transformer&amp;#39;s pre-trained checkpoints&lt;/a&gt;. I hit several issues:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/magenta/magenta/issues/1962&quot;&gt;Magenta install fails for Python &amp;gt;= 3.8 &lt;/a&gt; (worked around via &lt;a href=&quot;https://www.anaconda.com/&quot;&gt;Anaconda&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;The default optimizer (&lt;code&gt;AdafactorOptimizer&lt;/code&gt;) appeared to be incompatible with the version of Tensorflow Magenta installed (worked around via &lt;code&gt;--hparams=optimizer=Adam,...&lt;/code&gt;)&lt;/li&gt;
&lt;li&gt;I couldn&amp;#39;t use my GPU to train because it didn&amp;#39;t have enough memory&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/magenta/magenta/issues/1862&quot;&gt;Tensor2Tensor terminated on &amp;quot;key not found&amp;quot; errors&lt;/a&gt; (worked around with a newer version, as noted in the linked GitHub issue)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;results&quot;&gt;Results&lt;/h2&gt;
&lt;p&gt;After training for roughly a day (2,500 steps), the &lt;a href=&quot;https://log.schemescape.com/posts/machine-learning/../../assets/music-generation/mt-train-2500.mid&quot;&gt;resulting MIDI&lt;/a&gt; sounds mostly like random noise. It&amp;#39;s not clear to me if this was due to a bug in my pipeline or if I just needed to spend a lot more time training.&lt;/p&gt;
&lt;p&gt;Ultimately, I decided I didn&amp;#39;t understand the Magenta and Tensor2Tensor libraries well enough to make much progress (without investing an excessive amount of time), and I&amp;#39;d spent enough time troubleshooting issues already. &lt;a href=&quot;https://github.com/jaredkrinke/music-transformer-fine-tuning&quot;&gt;My training scripts are here&lt;/a&gt;.&lt;/p&gt;
&lt;h1 id=&quot;second-attempt&quot;&gt;Second attempt&lt;/h1&gt;
&lt;p&gt;Rather than give up on transformer-based music generation entirely, I searched around for a simpler codebase that I might be able to more easily understand and/or adapt. Here are a few I ran across:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/davidsvy/transformer-xl&quot;&gt;transformer-xl&lt;/a&gt; by &lt;a href=&quot;https://github.com/davidsvy&quot;&gt;davidsvy&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/COMP6248-Reproducability-Challenge/music-transformer-comp6248&quot;&gt;music-transformer-comp6248
&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/bearpelican/musicautobot&quot;&gt;MusicAutobot&lt;/a&gt; by &lt;a href=&quot;https://github.com/bearpelican&quot;&gt;Andrew Shaw&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The first one is a noted as a re-implementation from scratch of the ideas from the transformer/attention research papers (mostly the same ones I&amp;#39;d been looking at) using Tensorflow/Keras. The codebase seemed small enough that I could probably understand it all without too much trouble.&lt;/p&gt;
&lt;p&gt;I decided to move forward with the transformer-xl repository. I didn&amp;#39;t hit any issues with setup, which was a welcome development.&lt;/p&gt;
&lt;h2 id=&quot;training&quot;&gt;Training&lt;/h2&gt;
&lt;p&gt;As an initial test, I tried training on a fairly small corpus of 58 Scott Joplin MIDIs. I was able to decrease the batch size slightly to support training on my roughly 7 year old GPU. Training for 100 epochs only took about 7 hours.&lt;/p&gt;
&lt;p&gt;Note: although there was a preprocessing step to convert the MIDI files to another format, I didn&amp;#39;t notice any data generation/augmentation, as in the Magenta codebase.&lt;/p&gt;
&lt;h2 id=&quot;initial-results&quot;&gt;Initial results&lt;/h2&gt;
&lt;p&gt;Generating results was surprisingly slow (compared to using Magenta), but I haven&amp;#39;t investigated the reason for that yet.&lt;/p&gt;
&lt;p&gt;Regardless, the results sounded a (little) bit like music--a huge improvement from my previous attempt (which was just noise). Examples:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://log.schemescape.com/posts/machine-learning/../../assets/music-generation/train-100-1.midi&quot;&gt;Example 1&lt;/a&gt;: occasional glimpses of music&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://log.schemescape.com/posts/machine-learning/../../assets/music-generation/train-100-2.midi&quot;&gt;Example 2&lt;/a&gt;: pleasant notes with essentially no rhythm&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://log.schemescape.com/posts/machine-learning/../../assets/music-generation/train-100-3.midi&quot;&gt;Example 3&lt;/a&gt;: repetitive, again with inconsistent rhythm&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Unfortunately, the results after 250 epochs weren&amp;#39;t noticeably any better. It&amp;#39;s possible that the small corpus isn&amp;#39;t sufficient for training this model.&lt;/p&gt;
&lt;h1 id=&quot;next-steps&quot;&gt;Next steps&lt;/h1&gt;
&lt;p&gt;I started this project for fun, but after struggling with Python environments and coming to the realization that I have insufficient compute resources available, I&amp;#39;m reconsidering whether or not this is a good use of my time.&lt;/p&gt;
</content>
</entry>
<entry>
<title>Generating music using machine learning</title>
<id>https://log.schemescape.com/posts/machine-learning/generating-music.html</id>
<link rel="alternate" href="https://log.schemescape.com/posts/machine-learning/generating-music.html"/>
<updated>2022-04-26T00:00:00.000Z</updated>
<summary type="text">Let&apos;s see if I can use Google Brain&apos;s Music Transformer to generate ragtime music.</summary>
<content type="html">&lt;p&gt;Recent music generation results (e.g. &lt;a href=&quot;https://magenta.tensorflow.org/music-transformer&quot;&gt;Music Transformer: Generating Music with Long-Term Structure&lt;/a&gt;) are part of what piqued my interest in machine learning. After &lt;a href=&quot;https://log.schemescape.com/posts/machine-learning/mitx-6.036.html&quot;&gt;following an introduction to machine learning&lt;/a&gt;, it&amp;#39;s time for some experimentation.&lt;/p&gt;
&lt;p&gt;First up: generating a &lt;a href=&quot;https://en.wikipedia.org/wiki/Ragtime&quot;&gt;ragtime&lt;/a&gt; piano piece.&lt;/p&gt;
&lt;h1 id=&quot;approaches&quot;&gt;Approaches&lt;/h1&gt;
&lt;p&gt;The most compelling generated music I&amp;#39;ve seen thus far comes from Google Brain, namely their &lt;a href=&quot;https://magenta.tensorflow.org/performance-rnn&quot;&gt;Performance RNN&lt;/a&gt; and &lt;a href=&quot;https://magenta.tensorflow.org/music-transformer&quot;&gt;Music Transformer&lt;/a&gt; papers. The associated GitHub repositories appear to contain models that have been pre-trained on various corpora (e.g. a &lt;a href=&quot;https://www.piano-e-competition.com/&quot;&gt;piano competition&amp;#39;s MIDI recordings&lt;/a&gt;). It&amp;#39;s also possible to train using a new corpus. The trained models can generate continuations based on a primer or generate unconditioned music &amp;quot;from scratch&amp;quot;.&lt;/p&gt;
&lt;p&gt;Here are several approaches I&amp;#39;m investigating for generating a ragtime piece:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Condition pre-trained Performance RNN and Music Transformer models with existing ragtime music (either an intro or the first few measures) and generate a continuation&lt;/li&gt;
&lt;li&gt;Train a new model on a corpus of ragtime music, and then do unconditioned generation&lt;/li&gt;
&lt;li&gt;Train a new model on a ragtime corpus and generate a continuation from a ragtime primer&lt;/li&gt;
&lt;li&gt;Train a new model on a ragtime corpus and generate a continuation from an arbitrary primer&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;I don&amp;#39;t have any intuition for how large of a corpus is required to generate a decent model, so it&amp;#39;s possible that options 2 - 4 won&amp;#39;t be feasible for me (either because finding/generating such a training corpus is too difficult or the compute required to train the model is beyond what my computer can handle).&lt;/p&gt;
&lt;h1 id=&quot;using-pre-trained-models&quot;&gt;Using pre-trained models&lt;/h1&gt;
&lt;p&gt;Without installing anything locally, you can use the &lt;a href=&quot;https://colab.research.google.com/notebooks/magenta/piano_transformer/piano_transformer.ipynb&quot;&gt;Music Transformer notebook&lt;/a&gt; to generate music. There are several options:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Generate music &amp;quot;from scratch&amp;quot; (unconditional)&lt;/li&gt;
&lt;li&gt;Generate a continuation based on a primer&lt;/li&gt;
&lt;li&gt;Generate accompaniment for a (monophonic) melody&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;unconditional-generation&quot;&gt;Unconditional generation&lt;/h2&gt;
&lt;p&gt;Without providing a primer, I don&amp;#39;t think it&amp;#39;s possible to indicate what genre of music you&amp;#39;d like to generate. For example, the clip I got sounds like some sort of &lt;a href=&quot;https://log.schemescape.com/posts/machine-learning/../../assets/music-generation/mt-unconditioned.mid&quot;&gt;boogie-woogie folk march&lt;/a&gt;. Obviously this isn&amp;#39;t the genre that I was looking for (or, really, than anyone was looking for). Rather than continuing on randomly like this, I&amp;#39;ll investigate primed generation.&lt;/p&gt;
&lt;h2 id=&quot;continuations&quot;&gt;Continuations&lt;/h2&gt;
&lt;p&gt;The notebook linked above also supports providing a primer, either from a provided list or by uploading a MIDI file directly in the UI.&lt;/p&gt;
&lt;h3 id=&quot;cropping-midi-primers&quot;&gt;Cropping MIDI primers&lt;/h3&gt;
&lt;p&gt;The primer is included in the output, so I assume it should be reasonably short. My original plan was to edit down an existing ragtime MIDI using &lt;a href=&quot;https://musescore.org/en&quot;&gt;MuseScore&lt;/a&gt;, but MuseScore&amp;#39;s output appears to be incompatible with the &lt;a href=&quot;http://craffel.github.io/pretty-midi/&quot;&gt;pretty_midi&lt;/a&gt; module that the notebook uses, resulting in the following error:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;pretty_midi\pretty_midi.py:&lt;span class=&quot;hljs-number&quot;&gt;97&lt;/span&gt;: RuntimeWarning: Tempo, Key &lt;span class=&quot;hljs-keyword&quot;&gt;or&lt;/span&gt; &lt;span class=&quot;hljs-type&quot;&gt;Time&lt;/span&gt; signature change events &lt;span class=&quot;hljs-built_in&quot;&gt;found&lt;/span&gt; &lt;span class=&quot;hljs-keyword&quot;&gt;on&lt;/span&gt; non-zero tracks. This &lt;span class=&quot;hljs-keyword&quot;&gt;is&lt;/span&gt; &lt;span class=&quot;hljs-keyword&quot;&gt;not&lt;/span&gt; a &lt;span class=&quot;hljs-keyword&quot;&gt;valid&lt;/span&gt; &lt;span class=&quot;hljs-keyword&quot;&gt;type&lt;/span&gt; &lt;span class=&quot;hljs-number&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;hljs-keyword&quot;&gt;or&lt;/span&gt; &lt;span class=&quot;hljs-keyword&quot;&gt;type&lt;/span&gt; &lt;span class=&quot;hljs-number&quot;&gt;1&lt;/span&gt; MIDI file. Tempo, Key &lt;span class=&quot;hljs-keyword&quot;&gt;or&lt;/span&gt; &lt;span class=&quot;hljs-type&quot;&gt;Time&lt;/span&gt; Signature may be wrong.
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;My workaround was to switch to using &lt;a href=&quot;https://www.audacityteam.org/&quot;&gt;Audacity&lt;/a&gt; to crop my MIDI primer (and this worked without issue).&lt;/p&gt;
&lt;h3 id=&quot;example-continuations&quot;&gt;Example continuations&lt;/h3&gt;
&lt;p&gt;First, I tried using just the intro bars of some Scott Joplin rags:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://log.schemescape.com/posts/machine-learning/../../assets/music-generation/mt-continuation-intro-wall-street.mid&quot;&gt;Wall Street Rag intro&lt;/a&gt;: this generated an interesting continuation that sounded vaguely like a cross between ragtime and new age piano&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://log.schemescape.com/posts/machine-learning/../../assets/music-generation/mt-continuation-intro-magnetic.mid&quot;&gt;Magnetic Rag intro&lt;/a&gt;: this generated a continuation with a halting style that keeps repeating notes&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Overall, the results are impressive, but also somewhat alien. And definitely not ragtime.&lt;/p&gt;
&lt;p&gt;Next, I tried supplying the beginning of a few sections of Joplin rags:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Wall Street Rag&lt;ul&gt;
&lt;li&gt;The &lt;a href=&quot;https://log.schemescape.com/posts/machine-learning/../../assets/music-generation/mt-continuation-wall-street-1.mid&quot;&gt;first continuation&lt;/a&gt; gets a bit stuck on the primer, but then recovers nicely into a very short still-not-quite-ragtime section&lt;/li&gt;
&lt;li&gt;The &lt;a href=&quot;https://log.schemescape.com/posts/machine-learning/../../assets/music-generation/mt-continuation-wall-street-2.mid&quot;&gt;second continuation&lt;/a&gt; strays quickly and widely from ragtime (continuing the trend of &amp;quot;impressive, but not what I wanted&amp;quot;)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Maple Leaf Rag&lt;ul&gt;
&lt;li&gt;This &lt;a href=&quot;https://log.schemescape.com/posts/machine-learning/../../assets/music-generation/mt-continuation-maple-leaf.mid&quot;&gt;continuation&lt;/a&gt; seemed to ignore the primer and just started cycling through music I can only describe as &amp;quot;movie soundtrack&amp;quot;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Magnetic Rag&lt;ul&gt;
&lt;li&gt;The &lt;a href=&quot;https://log.schemescape.com/posts/machine-learning/../../assets/music-generation/mt-continuation-magnetic-1.mid&quot;&gt;first continuation&lt;/a&gt; was short, but rag-like!&lt;/li&gt;
&lt;li&gt;The &lt;a href=&quot;https://log.schemescape.com/posts/machine-learning/../../assets/music-generation/mt-continuation-magnetic-2.mid&quot;&gt;second continuation&lt;/a&gt; was similarly short, but promising&lt;/li&gt;
&lt;li&gt;The &lt;a href=&quot;https://log.schemescape.com/posts/machine-learning/../../assets/music-generation/mt-continuation-magnetic-3.mid&quot;&gt;third continuation&lt;/a&gt; was much longer, but... bad&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;accompaniment&quot;&gt;Accompaniment&lt;/h2&gt;
&lt;p&gt;Out of curiosity, I also tried generating an accompaniment (based on a monophonic melody that consists of the highest non-overlapping notes in the cropped MIDIs from the last section):&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://log.schemescape.com/posts/machine-learning/../../assets/music-generation/mt-accompaniment-magnetic.mid&quot;&gt;Magnetic Rag accompaniment&lt;/a&gt;: this was a baroquely ornamented mix of classical and blues&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;reflecting-on-pre-trained-models&quot;&gt;Reflecting on pre-trained models&lt;/h2&gt;
&lt;p&gt;Unsurprisingly, the generic pre-trained models I used, while undoubtedly impressive, seem best suited for exploration and amusement, rather than producing something focused on a particular genre.&lt;/p&gt;
&lt;p&gt;I suspect that the best path forward for this experiment is to train a new ragtime-focused model on a corpus of typical ragtime MIDIs. As noted earlier, it&amp;#39;s possible I won&amp;#39;t be able to find either a large enough corpus or enough compute power to produce a reasonable model, but if I &lt;em&gt;do&lt;/em&gt; succeed, I think the results will be more consistently rag-like.&lt;/p&gt;
</content>
</entry>
<entry>
<title>MITx - 6.036: Introduction to Machine Learning</title>
<id>https://log.schemescape.com/posts/machine-learning/mitx-6.036.html</id>
<link rel="alternate" href="https://log.schemescape.com/posts/machine-learning/mitx-6.036.html"/>
<updated>2022-04-24T00:00:00.000Z</updated>
<summary type="text">I&apos;m following a freely available MIT coure: Introduction to Machine Learning.</summary>
<content type="html">&lt;p&gt;As &lt;a href=&quot;https://log.schemescape.com/posts/machine-learning/getting-started.html&quot;&gt;noted previously&lt;/a&gt;, I&amp;#39;ve been researching machine learning (just for fun).&lt;/p&gt;
&lt;h1 id=&quot;mitx---6036&quot;&gt;MITx - 6.036&lt;/h1&gt;
&lt;p&gt;I&amp;#39;m starting with an undergraduate course from MIT that is online for free: &lt;a href=&quot;https://openlearninglibrary.mit.edu/courses/course-v1:MITx+6.036+1T2019/about&quot;&gt;MITx - 6.036: Introduction to Machine Learning&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Having just completed the course, here are some observations:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The lectures are excellent, but note that they&amp;#39;re theory- and math-heavy (and my math was rustier than I realized)&lt;/li&gt;
&lt;li&gt;I&amp;#39;d recommend learning about &lt;a href=&quot;https://numpy.org/&quot;&gt;NumPy&lt;/a&gt; &lt;em&gt;prior&lt;/em&gt; to starting this course (especially &lt;a href=&quot;https://numpy.org/doc/stable/user/basics.broadcasting.html&quot;&gt;element-wise operations and broadcasting&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;So far, there has been no need (and no benefit) to enabling GPU acceleration (and setting it up on Windows was painful, for &lt;a href=&quot;https://github.com/tensorflow/tensorflow/issues/48868&quot;&gt;reasons I still don&amp;#39;t understand&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;The provided code seems to be built for a previous version of TensorFlow&amp;#39;s Keras interface (although the &lt;a href=&quot;https://gist.github.com/jaredkrinke/0fed897dfbdf35af2c4eb388bfe0d754&quot;&gt;updates I have needed thus far&lt;/a&gt; were minor)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The course provides a great introduction to:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Classification&lt;/li&gt;
&lt;li&gt;Regression&lt;/li&gt;
&lt;li&gt;Neural networks&lt;/li&gt;
&lt;li&gt;Convolutional neural networks&lt;/li&gt;
&lt;li&gt;Recurrent neural networks&lt;/li&gt;
&lt;li&gt;Recommender systems&lt;/li&gt;
&lt;li&gt;Decision trees&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Note that the course &lt;em&gt;doesn&amp;#39;t&lt;/em&gt; cover some of the machine learning topics I&amp;#39;m most interested in:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Transformer_(machine_learning_model)&quot;&gt;Transformers&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Generative_adversarial_network&quot;&gt;Generative adversarial networks&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Overall, it was a fun course and good Python practice, but I wasn&amp;#39;t really inspired to go start a machine learning project because I&amp;#39;m not terribly interested in classification and regression problems at the moment.&lt;/p&gt;
</content>
</entry>
<entry>
<title>Getting started with machine learning</title>
<id>https://log.schemescape.com/posts/machine-learning/getting-started.html</id>
<link rel="alternate" href="https://log.schemescape.com/posts/machine-learning/getting-started.html"/>
<updated>2022-03-07T00:00:00.000Z</updated>
<summary type="text">For personal enrichment, I&apos;m playing around with machine learning.</summary>
<content type="html">&lt;p&gt;One of the reasons I decided to give &lt;a href=&quot;https://log.schemescape.com/posts/machine-learning/../programming-languages/python.html&quot;&gt;Python&lt;/a&gt; one last try is that Python is popular for machine learning, and machine learning is a topic I&amp;#39;m interested in.&lt;/p&gt;
&lt;h1 id=&quot;why&quot;&gt;Why?&lt;/h1&gt;
&lt;p&gt;Why am I interested in machine learning?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;It&amp;#39;s an area of computer science that has advanced significantly since I studied CS in school&lt;/li&gt;
&lt;li&gt;It has many unique practical applications (speech recognition, language translation, machine vision, generative art)&lt;/li&gt;
&lt;li&gt;I recently acquired a GPU that (as far as I know) is capable of accelerating machine learning pipelines&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&quot;first-steps&quot;&gt;First steps&lt;/h1&gt;
&lt;p&gt;As an introduction, I&amp;#39;m following MIT&amp;#39;s &lt;a href=&quot;https://openlearninglibrary.mit.edu/courses/course-v1:MITx+6.036+1T2019/about&quot;&gt;Introduction to Machine Learning (2020)&lt;/a&gt; class. It&amp;#39;s in Python and builds on &lt;a href=&quot;https://numpy.org/&quot;&gt;NumPy&lt;/a&gt;. The first 4 weeks focus on linear classifiers for binary classification.&lt;/p&gt;
&lt;p&gt;Although my math is rusty, my biggest struggle is actually with the NumPy API. Here is my list of grievances:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;NumPy implicitly &amp;quot;broadcasts&amp;quot; arrays into compatible shapes&lt;ul&gt;
&lt;li&gt;I assume this is for convenience, but all it&amp;#39;s done for me is silently hide bugs in my code&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;NumPy sometimes silently removes dimensions&lt;ul&gt;
&lt;li&gt;Again, this is probably for convenience, but all it&amp;#39;s done is trip me up -- I really wish &lt;code&gt;keepdims&lt;/code&gt; defaulted to &lt;code&gt;True&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;The API has a lot of cruft (e.g. a &lt;code&gt;matrix&lt;/code&gt; class that is no longer recommended for matrix computation)&lt;/li&gt;
&lt;li&gt;The documentation is frustratingly vague, and sometimes circular (e.g. &amp;quot;&lt;code&gt;*&lt;/code&gt; returns &lt;code&gt;self * value&lt;/code&gt;&amp;quot;)&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&quot;experimentation&quot;&gt;Experimentation&lt;/h1&gt;
&lt;h2 id=&quot;using-a-sample-data-set&quot;&gt;Using a sample data set&lt;/h2&gt;
&lt;p&gt;To get a better handle on NumPy, I&amp;#39;d like to actually attempt to create a linear classifier from scratch. A quick search led me to a &lt;a href=&quot;https://jamesmccaffrey.wordpress.com/2018/03/14/datasets-for-binary-classification/&quot;&gt;page with links to data sets for binary classification problems&lt;/a&gt;. I&amp;#39;m using &lt;a href=&quot;https://archive.ics.uci.edu/ml/datasets/banknote+authentication&quot;&gt;UCI Machine Learning Repository&amp;#39;s &amp;quot;banknote authentication&amp;quot; data set&lt;/a&gt; because the data format is simple (4 predictor variables and a 0 or 1 for the classification).&lt;/p&gt;
&lt;p&gt;To my surprise, simple algorithms (e.g. selecting random parameters) were able to correctly classify over 95% of examples. For what it&amp;#39;s worth, my code is posted &lt;a href=&quot;https://github.com/jaredkrinke/ml/tree/main/binary-classification&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&quot;solving-a-problem-from-scratch&quot;&gt;Solving a problem from scratch&lt;/h2&gt;
&lt;p&gt;I&amp;#39;d like to try solving a real world problem from scratch, but I don&amp;#39;t really have a problem in mind that lends itself to binary classification. For what it&amp;#39;s worth, here are some Kaggle data sets that might eventually inspire me:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://www.kaggle.com/vivovinco/nba-player-stats&quot;&gt;NBA players&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://www.kaggle.com/hacker-news/hacker-news&quot;&gt;Hacker News data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://www.kaggle.com/deepcontractor/musical-instrument-chord-classification&quot;&gt;Chord classification&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://www.kaggle.com/rounakbanik/the-movies-dataset&quot;&gt;Movie data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://www.kaggle.com/stackoverflow/stackoverflow&quot;&gt;Stack Overflow data&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</content>
</entry>
</feed>
